{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../Codes_1Dtree')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from data.graph_dataset import *\n",
    "from networks.gcnv6 import RecurrentFormulationNet, GraphNet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from networks.losses import LpLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    def __init__(self, d) -> None:\n",
    "        self.__dict__ = d\n",
    "    def setattr(self, attr_name, attr_value):\n",
    "        self.__dict__[attr_name] = attr_value\n",
    "\n",
    "args = objectview({\n",
    "    'n_fields': 1,\n",
    "    'n_meshfields': (13, 0),\n",
    "    'hidden_size': 512,\n",
    "    'n_layers': 10,\n",
    "    'n_timesteps': 201,\n",
    "    'n_previous_timesteps': 1,\n",
    "    'aggr': 'sum',\n",
    "    'act': 'relu',\n",
    "    'dropout': 0.2,\n",
    "    # 'use_hidden': True,\n",
    "    'device': torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
    "    'lr': 5e-5,\n",
    "    # 'lr_decay': 0.5,\n",
    "    # 'lr_decay_period': 50,\n",
    "    'weight_decay': 5e-4,\n",
    "    'n_epoch': 50000,\n",
    "    'alpha': 1.0,\n",
    "    'batch_size': 100,\n",
    "    'timestep': 201,\n",
    "    'timeslice_hops': 0,\n",
    "    'timeslice_steps': 1,\n",
    "    'n_data_per_batch': 1,\n",
    "    'forward_sequence': False,\n",
    "    'criterion': LpLoss(),\n",
    "    'plot': False\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = OneDDatasetBuilder(\n",
    "#     raw_dir='/data1/tam/datasets',\n",
    "#     # root_dir='/data1/tam/downloaded_datasets_node_features',\n",
    "#     root_dir='/data1/tam/test_datasets',\n",
    "#     sub_dir='processed',\n",
    "#     subjects=['10081'],\n",
    "#     time_names=[str(i).zfill(3) for i in range(201)],\n",
    "#     data_type = torch.float64,\n",
    "#     readme='edge_index(2xn_edge), node_attr(n_nodex10), pressure(n_nodex201)'\n",
    "# )\n",
    "dataset = OneDDatasetLoader(\n",
    "    root_dir='/data1/tam/downloaded_datasets_node_features',\n",
    "    # root_dir='/data1/tam/downloaded_datasets_edge_node_separated',\n",
    "    sub_dir='processed',\n",
    "    subjects='all',\n",
    "    time_names=[str(i).zfill(3) for i in range(201)],\n",
    "    data_type = torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try clipping output for better distribution\n",
    "# dataset = normalize(\n",
    "#     dataset=dataset,\n",
    "#     sub_dir='normalized',\n",
    "#     scaler_dict={\n",
    "#         'node_attr': ('minmax_scaler', 0, None),\n",
    "#         # 'edge_attr': ('minmax_scaler', 0, None),\n",
    "#         'pressure': ('minmax_scaler', None, None),\n",
    "#         # 'boundary_condition': ('minmax_scaler', None, None),\n",
    "#         'flowrate': ('robust_scaler', None, None),\n",
    "#         # 'pressure_dot': ('minmax_scaler', None, None),\n",
    "#         # 'flowrate_dot': ('robust_scaler', None, None),\n",
    "#         # 'time': ('minmax_scaler', None, None)\n",
    "#     }\n",
    "# )\n",
    "# dataset = OneDDatasetLoader(\n",
    "#     root_dir='/data1/tam/downloaded_datasets_node_features',\n",
    "#     sub_dir='normalized',\n",
    "#     subjects='all',\n",
    "#     time_names=[str(i).zfill(3) for i in range(201)],\n",
    "#     data_type = torch.float32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mbatchgraph_generation_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msub_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatched\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_gens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeslice_hops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeslice_hops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeslice_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeslice_steps\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# dataset = batchgraph_neighbor(\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     dataset,\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     sub_dir='batched',\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     batch_size=args.batch_size\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m OneDDatasetLoader(\n\u001b[1;32m     15\u001b[0m     root_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data1/tam/downloaded_datasets_node_features\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m     sub_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatched\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     data_type \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m/data1/tam/python_graph_utilities_v3/Run/../Codes_1Dtree/data/graph_dataset.py:323\u001b[0m, in \u001b[0;36mbatchgraph_generation_wise\u001b[0;34m(dataset, sub_dir, batch_gens, timestep, timeslice_hops, timeslice_steps)\u001b[0m\n\u001b[1;32m    321\u001b[0m _batch_gens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_gen \u001b[38;5;129;01min\u001b[39;00m batch_gens:\n\u001b[0;32m--> 323\u001b[0m     _batch_gen \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[43mbatch_gens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m], batch_gens[i][\u001b[38;5;241m1\u001b[39m]))]\n\u001b[1;32m    324\u001b[0m     _batch_gen \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m batch_gen[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    325\u001b[0m     _batch_gens \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _batch_gen\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dataset = batchgraph_generation_wise(\n",
    "    dataset,\n",
    "    sub_dir='batched',\n",
    "    batch_gens=[[0, 5, 1]],\n",
    "    timestep=args.timestep,\n",
    "    timeslice_hops=args.timeslice_hops,\n",
    "    timeslice_steps=args.timeslice_steps\n",
    ")\n",
    "# dataset = batchgraph_neighbor(\n",
    "#     dataset,\n",
    "#     sub_dir='batched',\n",
    "#     batch_size=args.batch_size\n",
    "# )\n",
    "dataset = OneDDatasetLoader(\n",
    "    root_dir='/data1/tam/downloaded_datasets_node_features',\n",
    "    sub_dir='batched',\n",
    "    subjects='all',\n",
    "    time_names=[str(i).zfill(3) for i in range(201)],\n",
    "    data_type = torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_loader) = dataset_to_loader(\n",
    "    dataset=dataset,\n",
    "    data_subset_dict={\n",
    "        'train': list(range(0, 2))\n",
    "    },\n",
    "    n_data_per_batch=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold_size = 2\n",
    "# fold = [list(range(i*fold_size, (i+1)*fold_size)) for i in range(8)]\n",
    "# n_train_fold = 5\n",
    "\n",
    "# for i in range(n_train_fold):\n",
    "#     test_subset = fold[i]\n",
    "#     train_subset = []\n",
    "#     for j in range(n_train_fold):\n",
    "#         if j != i:\n",
    "#             train_subset += fold[j]\n",
    "\n",
    "(train_loader, test_loader) = dataset_to_loader(\n",
    "    dataset=dataset,\n",
    "    data_subset_dict={\n",
    "        'train': list(range(0, 30)),\n",
    "        'test': list(range(30, 35))\n",
    "    },\n",
    "    n_data_per_batch=args.n_data_per_batch\n",
    ")\n",
    "\n",
    "# train_set, test_set = dataset_to_loader(\n",
    "#     dataset=dataset,\n",
    "#     data_subset_dict={\n",
    "#         'train': list(range(6, 36)),\n",
    "#         'test': list(range(0, 5))\n",
    "#     },\n",
    "#     n_data_per_batch=args.n_data_per_batch\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model initializing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GraphNet(\n",
    "#     n_fields=args.n_fields,\n",
    "#     n_meshfields=args.n_meshfields,\n",
    "#     hidden_size=args.hidden_size,\n",
    "#     n_layers=args.n_layers,\n",
    "#     n_previous_timesteps=args.n_previous_timesteps,\n",
    "#     # act=args.act,\n",
    "#     dropout=args.dropout,\n",
    "#     # use_hidden=args.use_hidden\n",
    "# )\n",
    "# setattr(model, 'name', 'model_GCN_LSTM')\n",
    "# model = model.to(args.device)\n",
    "# model.load_state_dict(torch.load(f'models/{model.name}_node2_epoch140.pth', map_location=args.device) )\n",
    "# optimizer1 = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "# optimizer2 = torch.optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "# setattr(args, 'optimizer', optimizer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphNet(\n",
    "    n_fields=args.n_fields,\n",
    "    n_meshfields=args.n_meshfields,\n",
    "    n_timesteps=args.n_timesteps,\n",
    "    hidden_size=args.hidden_size,\n",
    "    n_layers=args.n_layers,\n",
    "    n_previous_timesteps=args.n_previous_timesteps,\n",
    "    # act=args.act,\n",
    "    dropout=args.dropout,\n",
    "    # use_hidden=args.use_hidden\n",
    ")\n",
    "setattr(model, 'name', 'model_GraphUNet')\n",
    "model = model.to(args.device)\n",
    "# model.load_state_dict(torch.load(f'models/{model.name}_node2_epoch6000.pth', map_location=args.device) )\n",
    "optimizer1 = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "setattr(args, 'optimizer', optimizer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, args):\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    ##\n",
    "    F_true = torch.cat([data.pressure.unsqueeze(2)], dim=2) \\\n",
    "                .float().to(args.device)\n",
    "    ##\n",
    "    edge_index = torch.cat([data.edge_index, torch.flip(data.edge_index, dims=[0])], dim=1).to(args.device)\n",
    "    \n",
    "    ##\n",
    "    meshfield = (data.node_attr.float().to(args.device), None)\n",
    "\n",
    "    ##\n",
    "    model.train()\n",
    "    args.optimizer.zero_grad()\n",
    "\n",
    "    F_pred = model.forward(\n",
    "        edge_index=edge_index,\n",
    "        meshfield=meshfield\n",
    "    )\n",
    "    ##\n",
    "    \n",
    "    loss = args.criterion(F_pred, F_true)\n",
    "    loss.backward()\n",
    "    args.optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def eval(model, data, args):\n",
    "    ##\n",
    "    F_true = torch.cat([data.pressure.unsqueeze(2)], dim=2) \\\n",
    "                .float().to(args.device)\n",
    "\n",
    "    ##\n",
    "    edge_index = torch.cat([data.edge_index, torch.flip(data.edge_index, dims=[0])], dim=1).to(args.device)\n",
    "    ##\n",
    "    meshfield = (data.node_attr.float().to(args.device), None)\n",
    "    ##\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        F_pred = model.forward(\n",
    "            edge_index=edge_index,\n",
    "            meshfield=meshfield\n",
    "        )\n",
    "    ##\n",
    "    loss = args.criterion(F_pred, F_true)\n",
    "        \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "start_epoch = 0\n",
    "for epoch in range(args.n_epoch):\n",
    "    CUDA_LAUNCH_BLOCKING=1\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##\n",
    "    # if epoch % 100 == 0:\n",
    "    #     if args.n_timesteps < 100:\n",
    "    #         args.n_timesteps *= 2\n",
    "    train_loss = 0\n",
    "    for i in range(train_loader.__len__()):\n",
    "        data = next(iter(train_loader))\n",
    "        train_loss += train(model=model, data=data, args=args)\n",
    "    train_loss /= train_loader.__len__()\n",
    "\n",
    "    eval_loss = 0\n",
    "    for i in range(test_loader.__len__()):\n",
    "        data = next(iter(test_loader))\n",
    "        eval_loss += eval(model=model, data=data, args=args)\n",
    "    eval_loss /= test_loader.__len__()\n",
    "    \n",
    "    print(f'Epoch {epoch}: train loss = {train_loss}; eval loss = {eval_loss}')\n",
    "    train_loss = 0\n",
    "    eval_loss = 0\n",
    "    # else:\n",
    "        # print(f'Epoch {epoch}.')\n",
    "        \n",
    "    if (epoch+1) % 20 == 0:\n",
    "        torch.save(model.state_dict(), f'models/{model.name}_node2_epoch{start_epoch+epoch+1}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tam_geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
