{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../Codes_1Dtree')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from data.graph_dataset import OneDDatasetBuilder, OneDDatasetLoader, normalize, dataset_to_loader\n",
    "# from networks.gcn import GraphUNet, RecurrentFormulationNet\n",
    "from networks.gcnv2 import GraphUNetv2, RecurrentFormulationNet_hidden\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.graph_dataset import batchgraph_generation_wise, batchgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    def __init__(self, d) -> None:\n",
    "        self.__dict__ = d\n",
    "    def setattr(self, attr_name, attr_value):\n",
    "        self.__dict__[attr_name] = attr_value\n",
    "\n",
    "args = objectview({\n",
    "    'n_field': 2,\n",
    "    'n_meshfield': 16,\n",
    "    'hidden_size': 128,\n",
    "    'latent_size': 128,\n",
    "    'aggr': 'sum',\n",
    "    'act': 'mish',\n",
    "    'dropout': 0.2,\n",
    "    'device': torch.device('cuda:1' if torch.cuda.is_available() else 'cpu'),\n",
    "    'lr': 1e-6,\n",
    "    'weight_decay': 5e-3,\n",
    "    'n_epoch': 200,\n",
    "    'alpha': 0.5,\n",
    "    'timestep': None,\n",
    "    'timeslice_hops': 1,\n",
    "    'timeslice_steps': 1,\n",
    "    'n_data_per_batch': 3,\n",
    "    'criterion': torch.nn.MSELoss(),\n",
    "    'plot': False\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = OneDDatasetBuilder(\n",
    "#     raw_dir='/data1/tam/datasets',\n",
    "#     root_dir='/data1/tam/downloaded_datasets_Static_v1',\n",
    "#     sub_dir='processed',\n",
    "#     subjects='all',\n",
    "#     time_names=[str(i).zfill(3) for i in range(201)],\n",
    "#     data_type = torch.float32,\n",
    "#     readme='edge_index(2xn_edge), node_attr(n_nodex10), pressure+flowrate(n_nodex201)'\n",
    "# )\n",
    "# dataset = OneDDatasetLoader(\n",
    "#     root_dir='/data1/tam/downloaded_datasets_Static_v1',\n",
    "#     sub_dir='processed',\n",
    "#     subjects='all',\n",
    "#     time_names=[str(i).zfill(3) for i in range(201)],\n",
    "#     data_type = torch.float32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = normalize(\n",
    "#     dataset=dataset,\n",
    "#     sub_dir='normalized',\n",
    "#     scaler_dict={\n",
    "#         'node_attr': ('minmax_scaler', 0, None),\n",
    "#         'pressure': ('minmax_scaler', None, 0.99),\n",
    "#         'flowrate': ('minmax_scaler', None, 0.99),\n",
    "#         'pressure_dot': ('minmax_scaler', None, 0.99),\n",
    "#         'flowrate_dot': ('minmax_scaler', None, 0.99),\n",
    "#         'time': ('minmax_scaler', None, None)\n",
    "#     }\n",
    "# )\n",
    "# dataset = OneDDatasetLoader(\n",
    "#     root_dir='/data1/tam/downloaded_datasets_Static_v1',\n",
    "#     sub_dir='normalized',\n",
    "#     subjects='all',\n",
    "#     time_names=[str(i).zfill(3) for i in range(201)],\n",
    "#     data_type = torch.float32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = batchgraph_generation_wise(\n",
    "#     dataset,\n",
    "#     sub_dir='batched',\n",
    "#     batch_gens=[[14,15]],\n",
    "#     timestep=args.timestep,\n",
    "#     timeslice_hops=args.timeslice_hops,\n",
    "#     timeslice_steps=args.timeslice_steps\n",
    "# )\n",
    "# dataset = batchgraph(\n",
    "#     dataset,\n",
    "#     sub_dir='batched',\n",
    "#     batchsize=1000,\n",
    "#     timestep=args.timestep,\n",
    "#     timeslice_hops=args.timeslice_hops,\n",
    "#     timeslice_steps=args.timeslice_steps\n",
    "# )\n",
    "dataset = OneDDatasetLoader(\n",
    "    root_dir='/data1/tam/downloaded_datasets_Static_v1',\n",
    "    sub_dir='batched',\n",
    "    subjects='all',\n",
    "    time_names=[str(i).zfill(3) for i in range(201)],\n",
    "    data_type = torch.float32\n",
    ")\n",
    "if args.plot:\n",
    "    print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_size = 5\n",
    "fold = [list(range(i*fold_size, (i+1)*fold_size)) for i in range(8)]\n",
    "n_train_fold = 7\n",
    "\n",
    "# for i in range(n_train_fold):\n",
    "#     test_subset = fold[i]\n",
    "#     train_subset = []\n",
    "#     for j in range(n_train_fold):\n",
    "#         if j != i:\n",
    "#             train_subset += fold[j]\n",
    "\n",
    "# (train_loader, test_loader) = dataset_to_loader(\n",
    "#     dataset=dataset,\n",
    "#     data_subset_dict={\n",
    "#         'train': list(range(5, 35)),\n",
    "#         'test': list(range(0, 5))\n",
    "#     },\n",
    "#     n_data_per_batch=args.n_data_per_batch\n",
    "# )\n",
    "\n",
    "# train_set, test_set = dataset_to_loader(\n",
    "#     dataset=dataset,\n",
    "#     data_subset_dict={\n",
    "#         'train': list(range(6, 36)),\n",
    "#         'test': list(range(0, 5))\n",
    "#     },\n",
    "#     n_data_per_batch=args.n_data_per_batch\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model initializing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentFormulationNet_hidden(\n",
    "    n_field=args.n_field,\n",
    "    n_meshfield=args.n_meshfield,\n",
    "    hidden_size=args.hidden_size,\n",
    "    latent_size=args.latent_size,\n",
    "    act=args.act,\n",
    "    use_time_feature=True,\n",
    "    dropout=args.dropout\n",
    ")\n",
    "setattr(model, 'name', 'PARC_GCN_UNet_full')\n",
    "model = model.to(args.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "setattr(args, 'optimizer', optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, args):\n",
    "    ##\n",
    "    F_true = torch.cat([data.pressure.unsqueeze(2), data.flowrate.unsqueeze(2)], dim=2) \\\n",
    "                .float().to(args.device)\n",
    "    F_dot_true = torch.cat([data.pressure_dot.unsqueeze(2), data.flowrate_dot.unsqueeze(2)], dim=2) \\\n",
    "                .float().to(args.device)\n",
    "    ##\n",
    "    F_0 = F_true[:,0,:]\n",
    "    # edge_index = data.edge_index.to(args.device)\n",
    "    edge_index = torch.cat([data.edge_index, torch.flip(data.edge_index, dims=[0])], dim=1).to(args.device)\n",
    "    node_attr = data.node_attr.float().to(args.device)\n",
    "    F_true = F_true[:,1:,:]\n",
    "    F_dot_true = F_dot_true[:,1:,:]\n",
    "    time = data.time.float().to(args.device)\n",
    "    ##\n",
    "    F_pred, F_dot_pred = model.forward(\n",
    "        F_0=F_0,\n",
    "        edge_index=edge_index,\n",
    "        meshfield=node_attr,\n",
    "        time=time,\n",
    "        n_time=data.number_of_timesteps - 1,\n",
    "        device=args.device\n",
    "    )\n",
    "    ##\n",
    "    loss = args.criterion(F_pred, F_true)*args.alpha + (1.-args.alpha)*args.criterion(F_dot_pred, F_dot_true)\n",
    "    loss.backward()\n",
    "    args.optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def eval(model, data, args):\n",
    "    ##\n",
    "    F_true = torch.cat([data.pressure.unsqueeze(2), data.flowrate.unsqueeze(2)], dim=2) \\\n",
    "                .float().to(args.device)\n",
    "    F_dot_true = torch.cat([data.pressure_dot.unsqueeze(2), data.flowrate_dot.unsqueeze(2)], dim=2) \\\n",
    "                .float().to(args.device)\n",
    "    ##\n",
    "    F_0 = F_true[:,0,:]\n",
    "    # edge_index = data.edge_index.to(args.device)\n",
    "    edge_index = torch.cat([data.edge_index, torch.flip(data.edge_index, dims=[0])], dim=1).to(args.device)\n",
    "    node_attr = data.node_attr.float().to(args.device)\n",
    "    F_true = F_true[:,1:,:]\n",
    "    F_dot_true = F_dot_true[:,1:,:]\n",
    "    time = data.time.float().to(args.device)\n",
    "    ##\n",
    "    with torch.no_grad():\n",
    "        F_pred, F_dot_pred = model.forward(\n",
    "            F_0=F_0,\n",
    "            edge_index=edge_index,\n",
    "            meshfield=node_attr,\n",
    "            time=time,\n",
    "            n_time=data.number_of_timesteps - 1,\n",
    "            device=args.device\n",
    "        )\n",
    "        loss = args.criterion(F_pred, F_true)*args.alpha + (1.-args.alpha)*args.criterion(F_dot_pred, F_dot_true)\n",
    "        \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlfm/anaconda3/envs/geometric/lib/python3.11/site-packages/torch_geometric/utils/sparse.py:176: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  return adj.to_sparse_csr()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss = 0.06772686184309865; eval loss = 0.21989046819884367\n",
      "Epoch 1: train loss = 0.21634605448762373; eval loss = 0.05665095436452615\n",
      "Epoch 2: train loss = 0.2109537600916251; eval loss = 0.05320758530587861\n",
      "Epoch 3: train loss = 0.20783944710357943; eval loss = 0.05921515276787257\n",
      "Epoch 4: train loss = 0.20504433123391697; eval loss = 0.09245611704660184\n",
      "Epoch 5: train loss = 0.20209003551256435; eval loss = 0.08881558974583943\n",
      "Epoch 6: train loss = 0.2012068496669753; eval loss = 0.06410570337314798\n",
      "Epoch 7: train loss = 0.05109243253135641; eval loss = 0.19917232641065963\n",
      "Epoch 8: train loss = 0.19760264342811507; eval loss = 0.04571401745532498\n",
      "Epoch 9: train loss = 0.19500909937315583; eval loss = 0.04410594084648171\n",
      "Epoch 10: train loss = 0.19390353452029768; eval loss = 0.049933921056564405\n",
      "Epoch 11: train loss = 0.19747783821044637; eval loss = 0.08594767357965913\n",
      "Epoch 12: train loss = 0.19588937861261835; eval loss = 0.08143026487092779\n",
      "Epoch 13: train loss = 0.19383431960970668; eval loss = 0.057237210410712946\n",
      "Epoch 14: train loss = 0.04286329442550083; eval loss = 0.1905783675234727\n",
      "Epoch 15: train loss = 0.19041820160426867; eval loss = 0.041474917132144025\n",
      "Epoch 16: train loss = 0.19020663910307456; eval loss = 0.045504179792572756\n",
      "Epoch 17: train loss = 0.19147459408756842; eval loss = 0.0499589993345617\n",
      "Epoch 18: train loss = 0.19065574086357898; eval loss = 0.08781822590213834\n",
      "Epoch 19: train loss = 0.1891862626759534; eval loss = 0.0849494639069143\n",
      "Epoch 20: train loss = 0.18688508486848768; eval loss = 0.06315135278485039\n",
      "Epoch 21: train loss = 0.04725249351810683; eval loss = 0.1859864184651712\n",
      "Epoch 22: train loss = 0.18662537346939145; eval loss = 0.04350747691109927\n",
      "Epoch 23: train loss = 0.187540149502141; eval loss = 0.04570488262959201\n",
      "Epoch 24: train loss = 0.18452450234676174; eval loss = 0.053400091187219424\n",
      "Epoch 25: train loss = 0.18474522502793475; eval loss = 0.08933371621550935\n",
      "Epoch 26: train loss = 0.17967912864866595; eval loss = 0.07946714405158553\n",
      "Epoch 27: train loss = 0.17781081843679233; eval loss = 0.0587924670691442\n",
      "Epoch 28: train loss = 0.03851664632987452; eval loss = 0.17266619476405057\n",
      "Epoch 29: train loss = 0.1719766304325533; eval loss = 0.03854558424967708\n",
      "Epoch 30: train loss = 0.16730107894000265; eval loss = 0.04679832396784214\n",
      "Epoch 31: train loss = 0.16019429087437148; eval loss = 0.059776062917227694\n",
      "Epoch 32: train loss = 0.15651507985773425; eval loss = 0.13062939062865095\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "total_train_loss = []\n",
    "total_eval_loss = []\n",
    "for epoch in range(args.n_epoch):\n",
    "    ##\n",
    "    test_subset = fold[epoch % n_train_fold]\n",
    "    train_subset = []\n",
    "    for j in range(n_train_fold):\n",
    "        if j != (epoch % n_train_fold):\n",
    "            train_subset += fold[j]\n",
    "    (train_loader, test_loader) = dataset_to_loader(\n",
    "        dataset=dataset,\n",
    "        data_subset_dict={\n",
    "            'train': train_subset,\n",
    "            'test': test_subset\n",
    "        },\n",
    "        n_data_per_batch=args.n_data_per_batch\n",
    "    )\n",
    "    ##\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loss = 0\n",
    "    for i in range(train_loader.__len__()):\n",
    "        data = next(iter(train_loader))\n",
    "        train_loss += train(model=model, data=data, args=args)\n",
    "    train_loss /= train_loader.__len__()\n",
    "    total_train_loss.append(train_loss)\n",
    "\n",
    "    eval_loss = 0\n",
    "    for i in range(test_loader.__len__()):\n",
    "        data = next(iter(test_loader))\n",
    "        eval_loss += eval(model=model, data=data, args=args)\n",
    "    eval_loss /= test_loader.__len__()\n",
    "    total_eval_loss.append(eval_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch}: train loss = {train_loss}; eval loss = {eval_loss}')\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        torch.save(model.state_dict(), f'models/{model.name}_node1_epoch{epoch+1}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
