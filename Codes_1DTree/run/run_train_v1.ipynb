{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data.graph_dataset import OneDDatasetBuilder, OneDDatasetLoader\n",
    "from data.pre_process import *\n",
    "from data.post_process import print_1D\n",
    "from networks.gcnv1 import GraphNet\n",
    "import matplotlib.pyplot as plt\n",
    "from networks.losses import LpLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    def __init__(self, d) -> None:\n",
    "        self.__dict__ = d\n",
    "    def setattr(self, attr_name, attr_value):\n",
    "        self.__dict__[attr_name] = attr_value\n",
    "\n",
    "args = objectview({\n",
    "    'n_fields': 1,\n",
    "    'n_meshfields': (9, 15),\n",
    "    'hidden_size': 512,\n",
    "    'n_layers': 10,\n",
    "    'n_timesteps': 201,\n",
    "    'n_previous_timesteps': 1,\n",
    "    'aggr': 'sum',\n",
    "    'act': 'relu',\n",
    "    'dropout': 0.15,\n",
    "    'device': torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
    "    'lr': 1e-5,\n",
    "    'weight_decay': 5e-4,\n",
    "    'n_epoch': 50000,\n",
    "    'alpha': 1.0,\n",
    "    'batch_size': 100,\n",
    "    'timestep': 201,\n",
    "    'timeslice_hops': 0,\n",
    "    'timeslice_steps': 1,\n",
    "    'n_data_per_batch': 2,\n",
    "    'forward_sequence': False,\n",
    "    'criterion': LpLoss(),\n",
    "    'plot': False\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build dataset\n",
    "# dataset = OneDDatasetBuilder(\n",
    "#     raw_dir='/data1/tam/datasets',\n",
    "#     root_dir='/data1/tam/downloaded_datasets_v2',\n",
    "#     sub_dir='processed',\n",
    "#     subjects='all',\n",
    "#     refined_max_length=4.,\n",
    "#     time_names=[str(i).zfill(3) for i in range(201)],\n",
    "#     data_type = torch.float64,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw dataset\n",
    "# dataset = OneDDatasetLoader(\n",
    "#     root_dir='/data1/tam/downloaded_datasets_v2',\n",
    "#     sub_dir='processed',\n",
    "#     subjects='all',\n",
    "#     time_names=[str(i).zfill(3) for i in range(201)],\n",
    "#     data_type = torch.float64,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize dataset\n",
    "# dataset = normalize(\n",
    "#     dataset=dataset,\n",
    "#     sub_dir='normalized',\n",
    "#     scaler_dict={\n",
    "#         'node_attr' : ['minmax_scaler']*9,\n",
    "#         'edge_attr' : ['minmax_scaler']*15,\n",
    "#         'pressure' : 'minmax_scaler',\n",
    "#     },\n",
    "#     clipping=5e-4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalized datasset\n",
    "# dataset = OneDDatasetLoader(\n",
    "#     root_dir='/data1/tam/downloaded_datasets_v2',\n",
    "#     sub_dir='normalized',\n",
    "#     subjects='all',\n",
    "#     time_names=[str(i).zfill(3) for i in range(201)],\n",
    "#     data_type = torch.float64,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch dataset\n",
    "# batched_dataset = batchgraph_generation_wise(\n",
    "#     sub_dir = 'batched',\n",
    "#     dataset=dataset,\n",
    "#     batch_gens=[[0,9], [10, 13], [14, 17], [18, 50]],\n",
    "#     subset_hops=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load batched dataset\n",
    "dataset = OneDDatasetLoader(\n",
    "    root_dir='/data1/tam/downloaded_datasets_v2',\n",
    "    sub_dir='batched',\n",
    "    subjects='all',\n",
    "    time_names=[str(i).zfill(3) for i in range(201)],\n",
    "    data_type = torch.float64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_loader, test_loader) = dataset_to_loader(\n",
    "    dataset=dataset,\n",
    "    data_subset_dict={\n",
    "        'train': list(range(0, 30)),\n",
    "        'test': list(range(30, 35))\n",
    "    },\n",
    "    n_data_per_batch=args.n_data_per_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphNet(\n",
       "  (act): ReLU()\n",
       "  (net1): GraphConv()\n",
       "  (net2): GraphUNet(512, 512, 512, depth=5, pool_ratios=[0.5, 0.5, 0.5, 0.5, 0.5])\n",
       "  (net3): MLP(512, 512, 201)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraphNet(\n",
    "    n_fields=args.n_fields,\n",
    "    n_meshfields=args.n_meshfields,\n",
    "    n_timesteps=args.n_timesteps,\n",
    "    hidden_size=args.hidden_size,\n",
    "    n_layers=args.n_layers,\n",
    "    n_previous_timesteps=args.n_previous_timesteps,\n",
    "    act=args.act,\n",
    ")\n",
    "setattr(model, 'name', 'model_GraphUNet')\n",
    "model = model.to(args.device)\n",
    "# model.load_state_dict(torch.load(f'models/{model.name}_node2_epoch6000.pth', map_location=args.device) )\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "setattr(args, 'optimizer', optimizer)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tam/.conda/envs/tam_geometric/lib/python3.11/site-packages/torch_geometric/utils/sparse.py:268: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  adj = torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss = 0.4693300951272249; eval loss = 0.28785794973373413\n",
      "Epoch 1: train loss = 0.19331734602650005; eval loss = 0.22585470974445343\n",
      "Epoch 2: train loss = 0.16500102157394092; eval loss = 0.2200707048177719\n",
      "Epoch 3: train loss = 0.1447904149691264; eval loss = 0.24198313057422638\n",
      "Epoch 4: train loss = 0.12717481292784213; eval loss = 0.2543887495994568\n",
      "Epoch 5: train loss = 0.11529046408832073; eval loss = 0.28710174560546875\n",
      "Epoch 6: train loss = 0.10557033084332942; eval loss = 0.3235306739807129\n",
      "Epoch 7: train loss = 0.09637945480644702; eval loss = 0.32248154282569885\n",
      "Epoch 8: train loss = 0.0899086520075798; eval loss = 0.31760627031326294\n",
      "Epoch 9: train loss = 0.08402706881364187; eval loss = 0.3083067536354065\n",
      "Epoch 10: train loss = 0.07861129275212685; eval loss = 0.3518325984477997\n",
      "Epoch 11: train loss = 0.07395327699681123; eval loss = 0.3065919578075409\n",
      "Epoch 12: train loss = 0.06995657042910655; eval loss = 0.3291291892528534\n",
      "Epoch 13: train loss = 0.06638309179494778; eval loss = 0.345411092042923\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     15\u001b[0m args\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m F_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mcriterion(F_pred, F_true)\n\u001b[1;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/data1/tam/python_graph_utilities_v3/Codes_1DTree/run/../networks/gcnv1.py:63\u001b[0m, in \u001b[0;36mGraphNet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m     62\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet1(x\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mnode_attr\u001b[38;5;241m.\u001b[39mfloat(), edge_index\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39medge_index, edge_attr\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 63\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet3(x)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mview((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_timesteps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_fields))\n",
      "File \u001b[0;32m~/.conda/envs/tam_geometric/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tam_geometric/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tam_geometric/lib/python3.11/site-packages/torch_geometric/nn/models/graph_unet.py:124\u001b[0m, in \u001b[0;36mGraphUNet.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m    121\u001b[0m     up[perm] \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    122\u001b[0m     x \u001b[38;5;241m=\u001b[39m res \u001b[38;5;241m+\u001b[39m up \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_res \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat((res, up), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_convs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/tam_geometric/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tam_geometric/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tam_geometric/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/.conda/envs/tam_geometric/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:110\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m    108\u001b[0m deg \u001b[38;5;241m=\u001b[39m scatter(edge_weight, idx, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dim_size\u001b[38;5;241m=\u001b[39mnum_nodes, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    109\u001b[0m deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m--> 110\u001b[0m \u001b[43mdeg_inv_sqrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeg_inv_sqrt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m edge_weight \u001b[38;5;241m=\u001b[39m deg_inv_sqrt[row] \u001b[38;5;241m*\u001b[39m edge_weight \u001b[38;5;241m*\u001b[39m deg_inv_sqrt[col]\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, edge_weight\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "start_epoch = 0\n",
    "for epoch in range(args.n_epoch):\n",
    "    CUDA_LAUCH_BLOCKING = 1\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    train_loss = 0\n",
    "    for i in range(train_loader.__len__()):\n",
    "        data = next(iter(train_loader))\n",
    "        data = data.to(args.device)\n",
    "        \n",
    "        F_true = torch.cat([data.pressure.unsqueeze(2)], dim=2) \\\n",
    "                    .float().to(args.device)\n",
    "        model.train()\n",
    "        args.optimizer.zero_grad()\n",
    "        F_pred = model.forward(data)\n",
    "\n",
    "        loss = args.criterion(F_pred, F_true)\n",
    "        loss.backward()\n",
    "        args.optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= train_loader.__len__()\n",
    "\n",
    "    eval_loss = 0\n",
    "    for i in range(test_loader.__len__()):\n",
    "        data = next(iter(test_loader))\n",
    "        data = data.to(args.device)\n",
    "\n",
    "        F_true = torch.cat([data.pressure.unsqueeze(2)], dim=2) \\\n",
    "                    .float().to(args.device)\n",
    "        model.eval()\n",
    "        F_pred = model.forward(data)\n",
    "\n",
    "        loss = args.criterion(F_pred, F_true)\n",
    "        eval_loss += loss.item()\n",
    "    eval_loss /= test_loader.__len__()\n",
    "\n",
    "    print(f'Epoch {epoch}: train loss = {train_loss}; eval loss = {eval_loss}')\n",
    "\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        torch.save(model.state_dict(), f'models/{model.name}_node1_epoch{start_epoch+epoch+1}.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tam_geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
